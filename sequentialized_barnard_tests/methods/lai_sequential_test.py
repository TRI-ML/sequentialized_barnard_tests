import numpy as np
from base import Decision, SequentialTestBase, TestResult
from numpy.typing import ArrayLike
from utils.utils_LAI_procedure import (
    bernoulli_KL,
    calc_gamma,
    calc_zeta,
    run_test_step_gamma_uniparameter,
)


class LaiSequentialTest(SequentialTestBase):
    def __init__(self, Nmax: int, alpha: float, min_gap: float = 0.01):
        assert min_gap > 0.0 and alpha > 0.0 and Nmax > 0

        self.Nmax = Nmax
        self.alpha = alpha
        self.min_gap = min_gap

        # Compute zeta and resulting univariate p0 / p1:
        self.zeta = calc_zeta(min_gap)
        self.theta_0 = 0.5
        self.theta_1 = 0.5 + self.zeta

        # Get appropriate calibration and assign self.c (regularizer of optimization problem)
        try:
            self.calibrate_regularizer()
        except:
            print(
                "Parameters do not match any pre-calibrated case, and calibration is not implemented at this time."
            )
            print("Setting to the reasonable but arbitrary value of 1e-4")
            self.set_arbitrary_regularizer(0.0001)

        # Compute gamma term in Lai algorithm
        self.gamma = calc_gamma(self.theta_0, self.theta_1, self.c)

        # Initialize test time and LAI state
        self.test_time = 0
        self.test_state = np.zeros(2)  # Note that the state here is [#1s, #1s + #-1s]

    def reset(self):
        """Reset critical test parameters (time <-- 0 and state <-- zeros(2))"""
        # Reset test time and LAI state
        self.test_time = 0
        self.test_state = np.zeros(2)  # Note that the state here is [#1s, #1s + #-1s]

    def run_on_sequence(
        self, sequence_0: ArrayLike, sequence_1: ArrayLike
    ) -> TestResult:
        """Run the Lai procedure on a sequence of data from p0 and p1. Modifies abstract class
        definition to account for the desire for a float representation of the sequence results.

        Args:
            sequence_0 (Arraylike): Sequence of i.i.d. bernoulli trials of Policy 0
            sequence_1 (Arraylike): Sequence of i.i.d. bernoulli trials of Policy 1

        Returns:
            result (TestResult): Test result class with decision and optional information
        """
        self.reset()
        if not (len(sequence_0) == len(sequence_1)):
            raise (ValueError("The two input sequences must have the same size."))
        elif not (len(sequence_0) <= self.Nmax):
            raise (ValueError("The sequences cannot exceed Nmax in length."))

        result = None
        for idx in range(len(sequence_0)):
            result = self.step(float(sequence_0[idx]), float(sequence_1[idx]))
            if not result.decision == Decision.FailToDecide:
                break

        return result

    def step(self, datum_0: float, datum_1: float) -> TestResult:
        """Run Lai procedure on n-th increment in a sequence of i.i.d. data. Subroutine of the
        run_on_sequence method.

        Args:
            datum_0 (float): single increment from i.i.d. data sequence generated by Policy 0
            datum_1 (float): single increment from i.i.d. data sequence generated by Policy 1

        Raises:
            ValueError: Error in the test_step update function leads to invalid decision result

        Returns:
            result (TestResult): Test result class with decision and optional information
        """
        assert np.isclose(datum_0, 0.0) or np.isclose(datum_0, 1.0)
        assert np.isclose(datum_1, 0.0) or np.isclose(datum_1, 1.0)

        # Iterate time
        self.test_time += 1

        # Compute difference
        difference_value = datum_1 - datum_0

        result = TestResult

        result.decision = Decision.FailToDecide
        result.info["time_of_decision"] = self.test_time

        if difference_value == 0.0:
            # Essentially, as if we received nothing, so update nothing...
            return result
        else:
            # There has been a relevant datum, so self.state[1] = (#1s + #-1s) increases by 1
            self.state[1] += 1
            if difference_value > 0.5:
                # There has been a 1, so self.state[0] = #1s increases by 1
                self.state[0] += 1

            sample_mean_of_test = self.state[0] / self.state[1]  # (#1s) / (#1s + #-1s)

            if bernoulli_KL(self.theta_0, sample_mean_of_test) >= bernoulli_KL(
                self.theta_1, sample_mean_of_test
            ):
                test_result_number = run_test_step_gamma_uniparameter(
                    self.c,
                    self.state[1],
                    sample_mean_of_test,
                    self.theta_0,
                    gamma=self.gamma,
                )
            else:
                test_result_number = run_test_step_gamma_uniparameter(
                    self.c,
                    self.state[1],
                    sample_mean_of_test,
                    self.theta_1,
                    gamma=self.gamma,
                )

            if test_result_number == 0:
                result.decision = Decision.AcceptNull
            elif test_result_number == 1:
                result.decision = Decision.AcceptAlternative
            elif test_result_number == 2:
                result.decision = Decision.FailToDecide
            else:
                raise ValueError(
                    "Invalid test result number in run_test_step_gamma_uniparameter"
                )

            return result

    def calibrate_regularizer(self):
        if self.Nmax == 500 and self.alpha == 0.05 and self.min_gap == 0.1:
            self.c = 0.000112805693
        else:
            raise NotImplementedError()

    def set_arbitrary_regularizer(self, c: float):
        """Set the regularizer to an arbitrary number. Useful for calibration purposes and
        for troubleshooting.

        Args:
            c (float): Regularizer for the optimization problem in Lai (1988). Lies in (0., 1.)
        """
        assert c > 0.0 and c < 1.0
        self.c = c
